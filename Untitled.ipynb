{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분 미니 프로젝트는 잘 마치셨나요? 여러분은 이번 노드를 통해 다음의 내용을 배웠습니다.\n",
    "\n",
    "    이미 잘 정제된 10개 클래스의 숫자 손글씨 데이터를 분류하는 classifier 만들기\n",
    "    정제되지 않은 웹캠 사진으로 부터 데이터 만들어보기\n",
    "    흑백 사진이 아닌 컬러 사진을 학습하는 classifier 만들기\n",
    "    분류하고자 하는 클래스의 개수를 마음대로 조절하기 (10개에서 3개로)\n",
    "\n",
    "\n",
    "## 1-2. 데이터를 준비합시다!\n",
    "텐서플로우(TF)의 표준 API_(Application Programming Interface, 응용 프로그램 프로그래밍 인터페이스)_ 인 tf.keras의 Sequential API를 이용하여 가위 바위 보 인식기를 만들 거예요. 구글(Google)에서 오픈소스로 제공하는 텐서플로우는 심볼릭 수학 라이브러리이자, 가장 널리 사용되고 있는 머신러닝 라이브러리 중 하나입니다. _머신러닝 안에 딥러닝이 포함됩니다. 더 완벽한 머신러닝이 딥러닝이라고 이해하면 된다._\n",
    "\n",
    "자, 그럼 TF 2.0이 설치된 환경에서 먼저 다음의 코드를 실행해 봅시다. 앞으로 보게 될 코드를 이해하지 못해도 가볍게 실행하는 것을 목표로 따라해보세요. 300개의 이미지를 인식시킨 지금, 필자도 완벽히 이해한 것은 아닙니다. 그러니 크게 호흡하고 그냥 읽고, 그냥 따라해보세요.\n",
    "```\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)   # Tensorflow의 버전 한 번 확인해주고\n",
    "\n",
    "```\n",
    "\n",
    "가위, 바위, 보 각 100장씩 사진을 찍어서 총 300장의 image data를 만들어야 합니다.\n",
    "    저 역시도 어느 세월에 찍고 있나 했지만, 역시 구글은 다 준비를 해놨습니다.\n",
    "    https://teachablemachine.withgoogle.com/\n",
    "에 들어가서 여러 각도, 여러 크기로 연속으로 사진을 찍기 바랍니다.\n",
    "\n",
    "다 찍었으면 'Download samples'를 눌러 저장합니다.\n",
    "\n",
    "추후를 위해 통일성을 유지해야 합니다. 통일성있게  rock_scissor_paper 라는 폴더 아래에 scissor, rock, paper 폴더를 만들어서 이미지를 저장합니다.\n",
    "\n",
    "이미지를 저장하고 속성에 들어가서 크기를 확인하면 224*224 픽셀인 것을 알 수 있습니다.\n",
    "이 이미지를 작게 resize해서 딥러닝이 가볍게 돌아갈 수 있도록 해줍시다. 이때 PIL 라이브러리를 이용할 건데, Python에서 이미지 처리를 할 때 사용하는 라이브러리 중 하나입니다.\n",
    "또, os 와 glob 모듈을 사용할 것입니다. 모듈은 함수나 변수 또는 클래스를 모아 놓은 파일입니다. 우리는 파이썬이 이미 모아둔 파일을 이용하기만 하면 됩니다.\n",
    "- os 모듈은 Operating System의 약자로서 운영체제에서 제공되는 여러 기능을 파이썬에서 수행할 수 있게 해줍니다. 예를 들어, 파이썬을 이용해 파일을 복사하거나 디렉터리를 생성하고 특정 디렉터리 내의 파일 목록을 구하고자 할 때 os 모듈을 사용하면 됩니다.\n",
    "- glob 모듈은 윈도우의 dir 명령어나 리눅스의 ls 명령어와 유사한 기능을 제공합니다. glob() 함수는 경로에 대응되는 모든 파일 및 디렉터리의 리스트를 반환합니다.\n",
    "그렇구나 읽고 포기하지 말고 아래 코드 봅시다.\n",
    "\n",
    "```\n",
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "#PIL로 사진도 resize하고, os랑 glob으로는 \n",
    "```\n",
    "\n",
    "그럼 이제 각 폴더마다 사진 사이즈 변경해봅시다.\n",
    "\n",
    "\n",
    "***\n",
    "## 1-3. 딥러닝 네트워크 설계하기\n",
    "\n",
    "다음의 코드는 tf.keras의 Sequential API를 이용하여 LeNet이라는 딥러닝 네트워크를 설계한 예입니다.\n",
    "--모르는 단어가 나와도 '그런가보다'하고 끝까지 그냥 읽으세요--\n",
    "8줄밖에 안되는 간단한 코드이지만, 가위, 바위, 보 분류기를 구현하는 데는 충분합니다.\n",
    "--ctrl+c, ctrl+v 해도 된다는 거지요--\n",
    "```\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "```\n",
    "   Conv2D 레이어의 첫 번째 인자는 사용하는 이미지 특징의 수입니다. 여기서는 16과 32를 사용했습니다. 가장 먼저 16개의 이미지 특징을, 그 뒤에 32개의 이미지 특징씩을 고려하겠다는 뜻입니다. 단순한 형태의 이미지는 이 정도의 특징만으로 충분할 수도 있지만,만약 강아지 얼굴 사진처럼 복잡한 영상이라면 더 큰 수를 넣는 것을 생각해 볼 수 있습니다.\n",
    "    Dense 레이어의 첫 번째 인자는 분류기에 사용되는 뉴런의 수 입니다. 뉴런이 더 많이 사용되면 보다 복잡한 분류기를 만들 수 있습니다. 가위, 바위, 보처럼 3가지가 아니라 한글의 모음, 자음 40개를 분류하고 싶다면 32보다 큰 64, 128 등을 고려해 볼 수 있을 것입니다.\n",
    "    마지막 Dense 레이어의 뉴런 수는 결과적으로 분류해 내야 하는 클래스 수로 지정하면 됩니다. 가위, 바위, 보 인식기에서는 3, 한글 인식기에서는 40가 되겠지요.\n",
    "\n",
    "우리가 만든 딥러닝 네트워크 모델을 확인해 보려면, model.summary() 코드를 이용하면 됩니다.\n",
    "\n",
    "***\n",
    "## 1-4. 딥러닝 네트워크 학습시키기\n",
    "\n",
    "우리가 만든 네트워크의 입력은 (데이터갯수, 이미지 크기 x, 이미지 크기 y, 채널수) 와 같은 형태를 가집니다. 이전 스텝에서 첫번째 레이어에 input_shape=(28,28,3)로 지정했던 것을 기억하시나요?\n",
    "그런데 print(x_train.shape) 을 해보면,(300, 28, 28) 로 채널수에 대한 정보가 없습니다. 따라서 (300, 28, 28, 3) 로 만들어 주어야 합니다 (여기서 채널수 1은 흑백 이미지를 의미합니다. 컬러 이미지라면 R, G, B 세 가지 값이 있기 때문에 3이겠죠?).\n",
    "```\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "그러면 이제 x_train 학습 데이터로 딥러닝 네트워크를 학습시켜 봅시다. 여기서 epochs=10 은 전체 300개의 데이터를 10번 반복 사용해서 학습을 시키라는 뜻입니다. 물론 model의 입력 정의에 형태를 맞춘 x_train_reshaped가 사용되어야겠죠. 자 그러면 코드를 실행해 봅시다.\n",
    "```\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "```\n",
    "***\n",
    "## 1-5. 얼마나 잘 만들었는지 확인하기\n",
    "\n",
    " 위의 인식 정확도는 학습용 데이터(x_train)을 가지고 구한 것입니다. 즉, 연습문제를 잘푸는 인공지능을 만든 거죠. 우리가 만든 딥러닝 네트워크는 실제 시험도 잘 볼 수 있을까요?\n",
    "자 그러면 시험용 데이터(x_test)를 가지고 확인해 봅시다.\n",
    "```\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "```\n",
    "\n",
    "어떤 데이터를 잘못 추론했을까? 눈으로 확인해 보자\n",
    "model.evaluate() 대신 model.predict()를 사용하면 model이 입력값을 보고 실제로 추론한 확률분포를 출력할 수 있습니다. 우리가 만든 model이란 사실 가위, 바위, 보 중 어느 것일지에 대한 확률값을 출력하는 함수입니다.\n",
    "이 함수의 출력값 즉 확률값이 가장 높은 형태가 바로 model이 추론한 형태가 되는 거죠.\n",
    "```\n",
    "predicted_result = model.predict(x_test_reshaped)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])\n",
    "\n",
    "#확인하기\n",
    "plt.imshow(x_test[idx],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "```\n",
    "그렇다면 model이 추론해 낸 숫자와 실제 라벨의 값이 다른 경우는 어떤 경우인지 직접 확인해 볼 수도 있겠습니다.\n",
    "```\n",
    "import random\n",
    "wrong_predict_list=[]\n",
    "for i, _ in enumerate(predicted_labels):\n",
    "    # i번째 test_labels과 y_test이 다른 경우만 모아 봅시다. \n",
    "    if predicted_labels[i] != y_test[i]:\n",
    "        wrong_predict_list.append(i)\n",
    "\n",
    "# wrong_predict_list 에서 랜덤하게 5개만 뽑아봅시다.\n",
    "samples = random.choices(population=wrong_predict_list, k=5)\n",
    "\n",
    "for n in samples:\n",
    "    print(\"예측확률분포: \" + str(predicted_result[n]))\n",
    "    print(\"라벨: \" + str(y_test[n]) + \", 예측결과: \" + str(predicted_labels[n]))\n",
    "    plt.imshow(x_test[n], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "\n",
    "```\n",
    "***\n",
    "## 1-6. 더 좋은 네트워크 만들어 보기\n",
    "\n",
    "딥러닝 네트워크의 구조 자체는 바꾸지 않으면서도 우리가 해볼 수 있는 것들이 있습니다. Step 3에서 살펴본 하이퍼파라미터들을 바꾸어 보는 것인데요. Conv2D 레이어에서 입력 이미지의 특징 수를 늘리거나 줄여 보거나, Dense 레이어에서 뉴런수를 바꾸어 보거나, 학습 반복 횟수인 epoch 값을 변경해 볼 수 있을 겁니다.\n",
    "```\n",
    "#바꿔 볼 수 있는 하이퍼파라미터들\n",
    "n_channel_1=16\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_reshaped, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
